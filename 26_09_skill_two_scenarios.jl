using JuMP
using NLPModelsJuMP, NLPModels
using Gurobi
using Distributions
using Random
using DataFrames
using CSV
using Printf

function print_iteration(k, args...)
    f(x) = Printf.@sprintf("%12.4e", x)
    println(lpad(k, 9), " ", join(f.(args), " "))
    return
end

###############################################################
# PARAMETERS
###############################################################

H = 4
J = 3
T·µà = 1
TÀ¢ = 1
Œû = 2

p = [1 / Œû for i in 1:Œû]

s = [1.0  0.0  0.0;  0.0  1.0  0.0; 0.0  0.0  1.0; 1.0  0.0  0.0]

d = [
    0.7  0.8  0.8  0.6  0.9  1.0  1.0  0.9  0.0  1.0
    0.2  0.2  1.0  0.9  0.7  0.7  0.4  1.0  0.3  0.7
    0.5  0.6  0.5  0.1  0.4  0.6  0.4  0.0  0.5  0.6
    0.5  1.4  0.3  1.0  0.8  0.8  0.2  0.8  0.6  0.6
    0.8  0.2  1.3  0.6  0.3  0.4  0.6  0.8  0.4  0.8
    0.3  0.4  0.9  0.2  0.6  1.0  0.4  0.3  0.4  0.6
]


Random.seed!(1234)

Œº = [1.2, 1.8, 1.6]
Œ£ = [0.5 0.0 0.0; 0.0 0.5 0.0; 0.0 0.0 0.5]
dÀ¢ = reshape(rand(MvNormal(Œº,Œ£), Œû ), (J,TÀ¢,Œû) )
dÀ¢ = round.(dŒæ , digits = 2)

#dÀ¢ = [1.2 , 1.8 , 3.2]

œá·µê·µÉÀ£ = fill(1, H ,J)


z·µñ = [7; 9; 11;7 ] * 1000
z·∂ú = z·µñ *2

z·µê = fill(0, H, J)

for h=1
        z·µê[h , 2] = (1/2) * z·µñ[h]
        z·µê[h , 3] = (3/4) * z·µñ[h]
end

for h=2
        z·µê[h , 3] = (1/2) * z·µñ[h]
        z·µê[h , 1] = (3/4) * z·µñ[h]
end

for h=3
        z·µê[h , 1] = (1/2) * z·µñ[h]
        z·µê[h , 2] = (3/4) * z·µñ[h]
end

for h=4
        z·µê[h , 2] = (1/2) * z·µñ[h]
        z·µê[h , 3] = (3/4) * z·µñ[h]
end

;


#########################################
# main model
#########################################

main = Model(Gurobi.Optimizer)
@variable(main, œà[1:H , 1:J], Bin)
@variable(main, 0 ‚â§ œá[1:H , 1:J])
@variable(main, Œ±[1:H , 1:J , 1:T·µà], Bin)
@variable(main, -1000000 ‚â§ Œ∏)


@objective(main, Min, sum( z·µñ[h] * œà[h,j] * (T·µà + TÀ¢) + z·µê[h,j] * œá[h,j] 
                           for h in 1:H for j in 1:J) + Œ∏);

con1_s1 = @constraint(main, demand_met[ j in 1:J , t in 1:T·µà ], 
    sum(Œ±[h,j,t] * (œà[h,j] + œá[h,j]) for h in 1:H ) ‚â• d[j,t] );

con2_s1 = @constraint(main, permanent_pool[h in 1:H , j in 1:J], œà[h,j] ‚â§ s[h,j]);

con3_s1 = @constraint(main, allocation_recruitment_training[h in 1:H , j in 1:J , t in 1:T·µà],
                      Œ±[h,j,t] ‚â§ œà[h,j] + 10 * œá[h,j] );

con4_s1 = @constraint(main, no_more_than_one_station[h in 1:H , t in 1:T·µà],
              sum(Œ±[h,j,t] for j in 1:J) ‚â§ 1  )

con4_s1 = @constraint(main, single_skilling_at_recruitment[h in 1:H , j in 1:J], 
    œá[h,j] ‚â§ ( 1 - œà[h,j] ) * œá·µê·µÉÀ£[h,j] );

con5_s1 = @constraint(main, training_recruited[ h in 1:H ], 
    sum(œá[h,j] for j in 1:J ) ‚â§ sum(œà[h,j] for j in 1:J) * J  );



##########################################
# delete this later
###########################################

œà_t = [1.0  0.0  0.0
 0.0  1.0  0.0
 0.0  0.0  0.0
 1.0  0.0  0.0]

œá_t = [0.0  0.0  0.0
 0.0  0.0  0.0
 0.0  0.0  0.0
 0.0  0.0  0.5]

Œ±_t =[ 1.0  0.0  0.0
    0.0   1.0  0.0
     0.0  0.0  0.0
     0.0  0.0   1.0]




################################################
# this function optimize the sub problem and generates the value for Œ±À¢
# Œ±À¢ stochastic alllocation
# Œ≥À¢ stochastic casual
################################################

function sub_solve(œà·µè , œá·µè)
    sub = Model(Gurobi.Optimizer)
    @variable(sub, Œ±À¢[1:H , 1:J , 1:TÀ¢ , 1:Œû], Bin )
    @variable(sub, 0 ‚â§ Œ≥À¢[1:J , 1:TÀ¢ , 1:Œû]);
    @objective(sub, Min,  (1/Œû) * sum(z·∂ú[j] * Œ≥À¢[j,t,Œæ] for j in 1:J for t in 1:TÀ¢ for Œæ in 1:Œû) )
    con1_S2 = @constraint(sub, demand_met[ j in 1:J , t in 1:TÀ¢ , Œæ in 1:Œû],
     sum(Œ±À¢[h,j,t,Œæ] * (œà·µè[h,j] + œá·µè[h,j]) for h in 1:H ) + Œ≥À¢[j,t,Œæ] ‚â• dÀ¢[j,t,Œæ]  );
    con2_s2 = @constraint(sub, permanent_allocability[h in 1:H , j in 1:J , t in 1:TÀ¢ , Œæ in 1:Œû],
            Œ±À¢[h,j,t,Œæ] ‚â§ œà·µè[h,j] + 10 * œá·µè[h,j] );
    con3_s2 = @constraint(sub, no_more_than_one_station[h in 1:H , t in 1:TÀ¢ , Œæ in 1:Œû],
           sum( Œ±À¢[h,j,t,Œæ] for j in 1:J) ‚â§ 1 );
    optimize!(sub)
    println("#####################################################################")
    println("#####################################################################")
    Œ±À¢ = value.(Œ±À¢)
    Œ≥À¢ = value.(Œ≥À¢)
    oÀ¢ = objective_value(sub)
    Œ±À¢ = round.(Œ±À¢ , digits = 2)
    Œ≥À¢ = round.(Œ≥À¢ , digits = 2)
    oÀ¢ = round.(oÀ¢ , digits = 2)
    return (Œ±À¢ , Œ≥À¢ , oÀ¢)
end


sub_solve(œà_t , œá_t)[1]

##################################################
# delete this later
##################################################
Œ±À¢_t = zeros(4,3,1,2)
Œ±À¢_t[:, :, 1, 1] = [1.0  0.0  0.0;
                     0.0  1.0  0.0;
                     0.0  0.0  0.0;
                     1.0  0.0  0.0]


Œ±À¢_t[:, :, 1, 2] = [ 1.0  0.0  0.0
 0.0  1.0  0.0
 0.0  0.0  0.0
 0.0  0.0  1.0]
Œ±À¢_t;

################################################################
# defining a function for second stage integer dual
###########################################

# when we want to get the dual the x (first stage variables are considered as fixed)
# when we want to get the coefficents of x, x should be variable
# therefore, we need to define two models one for dual and one for coefficient
###########################################
###############################################################




function sub_dual(œà·µè , œá·µè , Œ±À¢·µè)
    
    Œª = zeros(2,34)
    
    for Œû in 1:Œû 
        sub = Model(Gurobi.Optimizer) 
        @variable(sub,  Œ±À¢[1:H , 1:J , 1:TÀ¢ , Œû:Œû])
        @variable(sub, 0 ‚â§ Œ≥À¢[1:J , 1:TÀ¢ , Œû:Œû])
        @objective(sub, Min,  sum(z·∂ú[j] * Œ≥À¢[j,t,Œæ] for j in 1:J for t in 1:TÀ¢ for Œæ in Œû:Œû ) )
        
            for h in 1:H
            for j in 1:J
                for t in 1:TÀ¢
                        if Œ±À¢·µè[h , j , t , Œû] == 0
                            con = @constraint(sub, Œ±À¢[h,j,t,Œû] ‚â§ 0)
                        else
                            con = @constraint(sub, Œ±À¢[h,j,t,Œû] ‚â§ 1)
                            con = @constraint(sub, - Œ±À¢[h,j,t,Œû] ‚â§ - 1)
                        end
                end
            end
        end
          con1_S2 = @constraint(sub, demand_met[ j in 1:J , t in 1:TÀ¢ , Œæ in Œû:Œû],
       - sum(Œ±À¢[h,j,t,Œæ] * (œà·µè[h,j] + œá·µè[h,j]) for h in 1:H ) - Œ≥À¢[j,t,Œæ]  ‚â§ - dÀ¢[j,t,Œæ]   )
        con2_s2 = @constraint(sub, permanent_allocability[h in 1:H , j in 1:J , t in 1:TÀ¢ , Œæ in Œû:Œû],
                Œ±À¢[h,j,t,Œæ] ‚â§ œà·µè[h,j] + 10 * œá·µè[h,j] );
        con3_s2 = @constraint(sub, no_more_than_one_station[h in 1:H , t in 1:TÀ¢ , Œæ in Œû:Œû],
               sum( Œ±À¢[h,j,t,Œæ] for j in 1:J) ‚â§ 1 );
        
        con_less = all_constraints(sub, AffExpr, MOI.LessThan{Float64})
        optimize!(sub)
        Œª[ Œû , : ] = dual.(con_less)  
    end
    
    return Œª
    
   
      

    #no_con_equal = length(con_equal)
    #no_con_less = length(con_less)
    #no_all_con = no_con_equal + no_con_less;
    #@show no_con_equal
    #@show no_con_less
    #@show no_all_con;
    
    #print(sub)
    #return 
end

l = sub_dual(œà_t , œá_t , Œ±À¢_t)

#df_l = DataFrame(l, :auto)


@show l[1,:]
@show l[2,:]



#############################################
# function for coefficients of  ùúì  and  ùúí
#############################################

function sub_coef( Œ±À¢·µè)   
    h = zeros(2 , 34)
    T = zeros(34 , 24, 2)
    for Œû in 1:Œû
        sub = Model(Gurobi.Optimizer) 
        @variable(sub,   œà[1:H , 1:J], Bin )
        @variable(sub, 0 ‚â§ œá[1:H , 1:J])
        @variable(sub,  Œ±À¢[1:H, 1:J , 1:TÀ¢, Œû:Œû], Bin)
        @variable(sub, 0 ‚â§ Œ≥À¢[1:J , 1:TÀ¢ , Œû:Œû])
        @objective(sub, Min,  sum(z·∂ú[j] * Œ≥À¢[j,t,Œæ] for j in 1:J for t in 1:TÀ¢ for Œæ in Œû:Œû ) )
        for h in 1:H
                for j in 1:J
                    for t in 1:TÀ¢
                            if Œ±À¢·µè[h , j , t , Œû] == 0
                                con = @constraint(sub, Œ±À¢[h,j,t,Œû] ‚â§ 0)
                            else
                                con = @constraint(sub, Œ±À¢[h,j,t,Œû] ‚â§ 1)
                                con = @constraint(sub, - Œ±À¢[h,j,t,Œû] ‚â§ - 1)
                            end
                    end
                end
            end

            con1_S2 = @NLconstraint(sub, demand_met[ j in 1:J , t in 1:TÀ¢ , Œæ in Œû:Œû],
          - sum(Œ±À¢[h,j,t,Œæ] * (œà[h,j] + œá[h,j]) for h in 1:H ) - Œ≥À¢[j,t,Œæ] ‚â§ - dÀ¢[j,t,Œæ]     )
        con2_s2 = @constraint(sub, permanent_allocability[h in 1:H , j in 1:J , t in 1:TÀ¢ , Œæ in Œû:Œû],
                    Œ±À¢[h,j,t,Œæ] ‚â§ œà[h,j] + 10 * œá[h,j] );
        con3_s2 = @constraint(sub, no_more_than_one_station[h in 1:H , t in 1:TÀ¢ , Œæ in Œû:Œû],
                   sum( Œ±À¢[h,j,t,Œæ] for j in 1:J) ‚â§ 1 );
    
        # h #################
        nlp = MathOptNLPModel(sub)
        q = zeros(nlp.meta.nvar)
        h1 =nlp.meta.ucon
        h2 = cons(nlp , q)
        h[Œû , :]= h1 + h2
        
        # T ########################
        
        T[ : , : , Œû] = jac(nlp , q)[: , 1:24]
             
    end
    
    dt = DataFrame(T[:,:,1], :auto)
    CSV.write("D:\\dt.csv", dt)
    
    return (T,h)
    
    #vr = all_variables(sub)
    #vr_index = [vr[i].index.value for i in 1:length(vr)]
    #df = DataFrame(variable = vr , index = vr_index); 
    #@show df
    
    
    #jac(nlp, q)
    #T = jac(nlp, q)[ : , 1:24]
    #h1 = nlp.meta.ucon
    #h2 = cons(nlp , q)
    #h = h1 + h2
    #return (T,h1, h2, h)
end


sub_coef(Œ±À¢_t)


function initiate()
    for k in 1:10
        # main ############################
       optimize!(main)
        œà·µè = value.(œà)
        œá·µè = value.(œá)
        Œ∏·µè = value(Œ∏)
        all_var = all_variables(main)
        x·µè = all_var[1 : (H*J*2)]
        
        # sub_solve ############################
        Œ±À¢·µè = sub_solve(œà·µè , œá·µè)[1]
        Œ≥À¢·µè = sub_solve(œà·µè , œá·µè)[2]
        oÀ¢·µè = sub_solve(œà·µè , œá·µè)[3]
        
        # sub_dual ##############################
        Œª·µè  = sub_dual(œà·µè , œá·µè , Œ±À¢·µè)
        df_Œª·µè = DataFrame(Œª·µè , :auto)
        CSV.write("D:\\dt.csv", df_Œª·µè)
        
        # sub_coef ##########################
        T·µè = sub_coef(Œ±À¢·µè)[1]
        h·µè = sub_coef(Œ±À¢·µè)[2]
        
        # bender cut #######################
        e·µè = sum(p[i] * Œªt[i,j] *ht[i,j] for i in 1:2 for j in 1:34)
        E·µè = sum(p[i] * Œªt[i,:]' * Tt[:,:,i] for i in 1:2)
        w·µè = e·µè - E·µè * value.(x·µè)
        
        println("*********************************************************")
        println("         k    Œ∏·µè    w·µè ")
        print_iteration( k ,   Œ∏·µè  ,  w·µè)
        println("*********************************************************")
        
        if Œ∏·µè > w·µè - 1
            println("*********************************")
            println("       we have optimality        ")
            println("*********************************")
            break
        end
        cut = @constraint(main, Œ∏ ‚â• e·µè - E·µè * x·µè)
        @info "we add the cut $(cut) "
    end
end

initiate()







